{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d0244a",
   "metadata": {},
   "source": [
    "# Environment Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269a698b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/Live-Air-Quality'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Changing directory to main directory for easy data access\n",
    "working_directory = os.getenv(\"WORKING_DIRECTORY\")\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Checking the change\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b328e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git folder exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Checking the change\n",
    "print(\"Git folder exists:\", Path(\".git\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa717d07",
   "metadata": {},
   "source": [
    "# 1. Location IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d310d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a12eea90",
   "metadata": {},
   "source": [
    "# 2. Database Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d2a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckdb import DuckDBPyConnection\n",
    "from pathlib import Path\n",
    "from AQI.utils.common import create_directories\n",
    "\n",
    "import os\n",
    "import duckdb as ddb\n",
    "\n",
    "def database_connect(db_path: Path, s3_config: dict | None = None) -> DuckDBPyConnection:\n",
    "    \"\"\"\n",
    "    Connect to the DuckDB database at the specified path, and configures S3 access credentials for external data sources.\n",
    "\n",
    "    Args:\n",
    "        db_path (Path): Path to the DuckDB database file.\n",
    "        s3_config (dict | None): AWS S3 credentials. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        DuckDBPyConnection: Active database connection.\n",
    "    \"\"\"\n",
    "    conn = ddb.connect(str(db_path))\n",
    "\n",
    "    if s3_config:\n",
    "        conn.sql(f\"SET s3_access_key_id='{s3_config['access_key']}';\")\n",
    "        conn.sql(f\"SET s3_secret_access_key='{s3_config['secret_key']}';\")\n",
    "        conn.sql(f\"SET s3_region='{s3_config['region']}';\")\n",
    "        \n",
    "    return conn\n",
    "\n",
    "\n",
    "def database_close(conn: DuckDBPyConnection) -> None:\n",
    "    \"\"\"\n",
    "    Close the DuckDB database connection.\n",
    "\n",
    "    Args:\n",
    "        conn (DuckDBPyConnection): Active database connection to be closed.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if conn is not None:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "def database_aggregate_sql_paths(dir: Path) -> list[Path]:\n",
    "    \"\"\"\n",
    "    Recursively collect all `.sql` file paths from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        dir (Path): Root directory to search for SQL script files.\n",
    "\n",
    "    Returns:\n",
    "        list[Path]: Sorted list of paths to `.sql` files.\n",
    "    \"\"\"\n",
    "    sql_scripts = []\n",
    "    \n",
    "    for root, _, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".sql\"):\n",
    "                sql_scripts.append(Path(root) / file)\n",
    "    \n",
    "    return sorted(sql_scripts)\n",
    "\n",
    "\n",
    "def database_load_query(query_path: Path) -> str:\n",
    "    \"\"\"\n",
    "    Load a SQL query from a file.\n",
    "\n",
    "    Args:\n",
    "        query_path (Path): Path to the .sql file.\n",
    "\n",
    "    Returns:\n",
    "        str: The SQL query as a string.\n",
    "    \"\"\"\n",
    "    with open(query_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def database_execute_sql_query(conn: DuckDBPyConnection, query: str) -> None:\n",
    "    \"\"\"\n",
    "    Execute a SQL query on an active DuckDB connection.\n",
    "\n",
    "    Args:\n",
    "        conn (DuckDBPyConnection): Active DuckDB connection.\n",
    "        query (str): SQL query to execute.\n",
    "    \"\"\"\n",
    "    conn.execute(query)\n",
    "\n",
    "\n",
    "def database_initialize(db_path: Path, ddl_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Initialize the DuckDB database schema from .sql files in the given directory.\n",
    "\n",
    "    Args:\n",
    "        db_path (Path): Path to the DuckDB database file.\n",
    "        ddl_dir (Path): Directory containing .sql files for schema creation.\n",
    "    \"\"\"\n",
    "    create_directories([db_path.parent])\n",
    "\n",
    "    query_paths = database_aggregate_sql_paths(dir=ddl_dir)\n",
    "    conn = database_connect(db_path=db_path)\n",
    "\n",
    "    try:\n",
    "        for query_path in query_paths:\n",
    "            query = database_load_query(query_path=query_path)\n",
    "            database_execute_sql_query(conn=conn, query=query)\n",
    "    finally:\n",
    "        # Making sure connection is always closed\n",
    "        database_close(conn=conn)\n",
    "\n",
    "\n",
    "def database_drop(db_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Delete the DuckDB database file at the specified path.\n",
    "\n",
    "    Args:\n",
    "        db_path (Path): Path to the DuckDB database file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    db_path.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727bd55",
   "metadata": {},
   "source": [
    "### Testing commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a72cbfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_location = Path('artifacts/sql/air_quality.db')\n",
    "ddl_location = Path('src/AQI/sql/ddl')\n",
    "creation_or_deletion = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af94d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-01 13:40:55,177: INFO: common: Directory: artifacts/sql created successfully.]\n"
     ]
    }
   ],
   "source": [
    "database_initialize(db_path=db_location, ddl_dir=ddl_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d85973c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_drop(db_path=db_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd80c2b",
   "metadata": {},
   "source": [
    "# 3. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "234a2aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from jinja2 import Template\n",
    "from pathlib import Path\n",
    "\n",
    "from AQI.utils.common import load_json\n",
    "\n",
    "\n",
    "def insert_api_data(location_path: Path, db_path: Path, query_path: Path, start_date: str | None, end_date: str | None) -> None:\n",
    "    \"\"\"Insert OpenAQ data into database over a date range.\"\"\"\n",
    "    # Step 1: Get location IDs\n",
    "    location_ids = extract_location_ids(file_path=location_path)\n",
    "\n",
    "    # Step 2: Connect to DB\n",
    "    conn = database_connect(db_path=db_path)\n",
    "\n",
    "    try:\n",
    "        # Step 3: Load SQL template\n",
    "        query_template  = database_load_query(query_path)\n",
    "\n",
    "        # Step 4: Parse dates\n",
    "        start = parse_date(start_date)\n",
    "        end = parse_date(end_date, default=datetime.now())\n",
    "\n",
    "        # Step 5: Generate date range\n",
    "        date_range = generate_range(start, end)\n",
    "\n",
    "        # Step 6: Loop over IDs and months\n",
    "        for location_id in location_ids:\n",
    "            for curr_date in date_range:\n",
    "                api_path = render_openaq_path(location_id, year=curr_date.year, month=curr_date.month)\n",
    "                extraction_query = render_query(query_template , api_path)\n",
    "\n",
    "                try:\n",
    "                    database_execute_sql_query(conn=conn, query=extraction_query)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed: id={location_id}, date={curr_date:%Y-%m}, error={e}\")\n",
    "    \n",
    "    finally:\n",
    "        database_close(conn=conn)\n",
    "\n",
    "\n",
    "def extract_location_ids(file_path: Path) -> list[str]:\n",
    "    \"\"\"Extract location IDs as strings from a JSON file.\"\"\"\n",
    "    locations = load_json(file_path)\n",
    "    return [str(id) for id in locations.keys()]\n",
    "\n",
    "\n",
    "def parse_date(date_str: str | None, default: datetime | None = None) -> datetime:\n",
    "    \"\"\"Parse YYYY-MM string into datetime, fallback to default or now().\"\"\"\n",
    "    if date_str:\n",
    "        return datetime.strptime(date_str, \"%Y-%m\")\n",
    "    return default or datetime.now()\n",
    "\n",
    "\n",
    "def generate_range(start: datetime, end: datetime) -> list[datetime]:\n",
    "    \"\"\"Return list of month starts between start and end (inclusive).\"\"\"\n",
    "    return [start  + relativedelta(months=i) for i in range((end.year - start.year) * 12 + (end.month - start.month + 1))]\n",
    "\n",
    "\n",
    "def render_query(query: str, api_path: str) -> str:\n",
    "    \"\"\"Render SQL query with template substitution.\"\"\"\n",
    "    return Template(query).render(data_file_path=api_path)\n",
    "\n",
    "\n",
    "def render_openaq_path(location_id: str, year: int, month: int) -> str:\n",
    "    \"\"\"Generate OpenAQ S3 path for a location and month.\"\"\"\n",
    "    return f\"s3://openaq-data-archive/records/csv.gz/locationid={location_id}/year={year}/month={month}/*.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66517f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
