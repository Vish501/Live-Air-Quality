{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d0244a",
   "metadata": {},
   "source": [
    "# Environment Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269a698b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/Live-Air-Quality'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Changing directory to main directory for easy data access\n",
    "working_directory = os.getenv(\"WORKING_DIRECTORY\")\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Checking the change\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b328e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git folder exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Checking the change\n",
    "print(\"Git folder exists:\", Path(\".git\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa717d07",
   "metadata": {},
   "source": [
    "# 1. Location IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1d310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from openaq import OpenAQ\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from AQI.utils.logger import get_logger\n",
    "from AQI.utils.common import create_directories, save_json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initializing the logger to test for exploration purposes\n",
    "logger = get_logger(\"test\")\n",
    "\n",
    "\n",
    "def get_location_ids(geo_grid: list[float], save_path: Path, search_limit: int = 100, retries: int = 3, delay: float = 2.0) -> dict[int, str]:\n",
    "    \"\"\"\n",
    "    Fetch location IDs from OpenAQ within a geo-grid and save to JSON.\n",
    "\n",
    "    Args:\n",
    "    - geo_grid (list[float]): Bounding box [lon1, lat1, lon2, lat2].\n",
    "    - save_path (Path): File path for saving results as JSON.\n",
    "    - search_limit (int, optional): Max number of locations to fetch. Default is 100.\n",
    "    - retries (int, optional): Number of retries if API call fails. Default is 3.\n",
    "    - delay (float, optional): Delay (in seconds) between retries. Default is 2.0.\n",
    "\n",
    "    Returns:\n",
    "    - dict: {location_id: location_name}\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            # Step 1: Initialize an authenticated OpenAQ client\n",
    "            client = setup_openaq()\n",
    "\n",
    "            # Step 2: Fetch sensor locations within bounding box\n",
    "            data = client.locations.list(bbox=geo_grid, limit=search_limit)\n",
    "            logger.info(f\"Fetched up to {search_limit} locations within {geo_grid}.\")\n",
    "\n",
    "            # Step 3: Transform results into a dictionary {id: name}\n",
    "            loc_info = {location.id: location.name for location in data.results}\n",
    "            logger.info(f\"Retrieved {len(loc_info)} sensor locations.\")\n",
    "\n",
    "            # Step 4: Verify integrity (paranoia check â€” shouldn't mismatch)\n",
    "            if len(data.results) != len(loc_info):\n",
    "                raise ValueError(\"Mismatch between results and constructed dictionary.\")\n",
    "\n",
    "            # Step 5: Save the dictionary to disk as JSON\n",
    "            create_directories([save_path.parent])          # ensure parent directory exists\n",
    "            save_json(save_path=save_path, data=loc_info)\n",
    "\n",
    "            return loc_info\n",
    "        \n",
    "        except ValueError as ve:\n",
    "            # Data integrity issue, no retry here\n",
    "            logger.error(f\"Mismatch between results and constructed dictionary.: {ve}\")\n",
    "            raise ve\n",
    "\n",
    "        except Exception as e:\n",
    "            # Error, retry\n",
    "            attempt += 1\n",
    "            logger.warning(f\"While obtaining location ids, attempt {attempt}/{retries} failed with error: {e}. Retrying in {delay}s...\")\n",
    "            if attempt >= retries:\n",
    "                logger.error(f\"Max retries reached for obtaining location ids. Raising exception.\")\n",
    "                raise e\n",
    "            time.sleep(delay)\n",
    "\n",
    "\n",
    "def setup_openaq(secret_env_var: str = \"OPENAQI_API_KEY\") -> OpenAQ:\n",
    "    \"\"\"\n",
    "    Load the OpenAQ API key from environment and return an authenticated OpenAQ client.\n",
    "\n",
    "    Args:\n",
    "    - secret_env_var (str, optional): Name of the environment variable holding the API key.\n",
    "\n",
    "    Returns:\n",
    "    - OpenAQ: An authenticated OpenAQ client object.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the API key is not found in the environment.\n",
    "    - Exception: If client creation fails for any other reason.\n",
    "    \"\"\"\n",
    "    # Load API key from environment variable\n",
    "    openaq_api = os.getenv(secret_env_var)\n",
    "\n",
    "    if openaq_api is None:\n",
    "        logger.error(\"Unable to find OpenAQ API key in environment.\")\n",
    "        raise ValueError(f\"{secret_env_var} not found or empty.\")\n",
    "    \n",
    "    try:\n",
    "        # Instantiate API client\n",
    "        client = OpenAQ(api_key=openaq_api)\n",
    "        logger.info(f\"Successfully initialized OpenAQ client.\")\n",
    "        return client\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error while creating OpenAQ client: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fcc0ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-02 12:50:17,146: INFO: 2151408928: Successfully initialized OpenAQ client.]\n",
      "[2025-09-02 12:50:18,472: INFO: 2151408928: Fetched up to 100 locations within [-74.25909, 40.477399, -73.700181, 40.917577].]\n",
      "[2025-09-02 12:50:18,473: INFO: 2151408928: Retrieved 52 sensor locations.]\n",
      "[2025-09-02 12:50:18,475: INFO: common: Directory: artifacts/data created successfully.]\n",
      "[2025-09-02 12:50:18,476: INFO: common: Directory: artifacts/data created successfully.]\n",
      "[2025-09-02 12:50:18,478: INFO: common: JSON file saved at: artifacts/data/sensor_locations.json]\n"
     ]
    }
   ],
   "source": [
    "save_path = Path('artifacts/data/sensor_locations.json')\n",
    "geo_grid = [-74.25909, 40.477399, -73.700181, 40.917577]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        get_location_ids(geo_grid=geo_grid, save_path=save_path, search_limit=100)\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12eea90",
   "metadata": {},
   "source": [
    "# 2. Database Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d2a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckdb import DuckDBPyConnection\n",
    "from pathlib import Path\n",
    "from AQI.utils.common import create_directories\n",
    "\n",
    "import os\n",
    "import duckdb as ddb\n",
    "\n",
    "def database_connect(db_path: Path, s3_config: dict | None = None) -> DuckDBPyConnection:\n",
    "    \"\"\"\n",
    "    Connect to the DuckDB database at the specified path, and configures S3 access credentials for external data sources.\n",
    "\n",
    "    Args:\n",
    "        db_path (Path): Path to the DuckDB database file.\n",
    "        s3_config (dict | None): AWS S3 credentials. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        DuckDBPyConnection: Active database connection.\n",
    "    \"\"\"\n",
    "    conn = ddb.connect(str(db_path))\n",
    "\n",
    "    if s3_config:\n",
    "        conn.sql(f\"SET s3_access_key_id='{s3_config['access_key']}';\")\n",
    "        conn.sql(f\"SET s3_secret_access_key='{s3_config['secret_key']}';\")\n",
    "        conn.sql(f\"SET s3_region='{s3_config['region']}';\")\n",
    "        \n",
    "    return conn\n",
    "\n",
    "\n",
    "def database_close(conn: DuckDBPyConnection) -> None:\n",
    "    \"\"\"\n",
    "    Close the DuckDB database connection.\n",
    "\n",
    "    Args:\n",
    "        conn (DuckDBPyConnection): Active database connection to be closed.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if conn is not None:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "def database_aggregate_sql_paths(dir: Path) -> list[Path]:\n",
    "    \"\"\"\n",
    "    Recursively collect all `.sql` file paths from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        dir (Path): Root directory to search for SQL script files.\n",
    "\n",
    "    Returns:\n",
    "        list[Path]: Sorted list of paths to `.sql` files.\n",
    "    \"\"\"\n",
    "    sql_scripts = []\n",
    "    \n",
    "    for root, _, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".sql\"):\n",
    "                sql_scripts.append(Path(root) / file)\n",
    "    \n",
    "    return sorted(sql_scripts)\n",
    "\n",
    "\n",
    "def database_load_query(query_path: Path) -> str:\n",
    "    \"\"\"\n",
    "    Load a SQL query from a file.\n",
    "\n",
    "    Args:\n",
    "        query_path (Path): Path to the .sql file.\n",
    "\n",
    "    Returns:\n",
    "        str: The SQL query as a string.\n",
    "    \"\"\"\n",
    "    with open(query_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def database_execute_sql_query(conn: DuckDBPyConnection, query: str) -> None:\n",
    "    \"\"\"\n",
    "    Execute a SQL query on an active DuckDB connection.\n",
    "\n",
    "    Args:\n",
    "        conn (DuckDBPyConnection): Active DuckDB connection.\n",
    "        query (str): SQL query to execute.\n",
    "    \"\"\"\n",
    "    conn.execute(query)\n",
    "\n",
    "\n",
    "def database_initialize(db_path: Path, ddl_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Initialize the DuckDB database schema from .sql files in the given directory.\n",
    "\n",
    "    Args:\n",
    "        db_path (Path): Path to the DuckDB database file.\n",
    "        ddl_dir (Path): Directory containing .sql files for schema creation.\n",
    "    \"\"\"\n",
    "    create_directories([db_path.parent])\n",
    "\n",
    "    query_paths = database_aggregate_sql_paths(dir=ddl_dir)\n",
    "    conn = database_connect(db_path=db_path)\n",
    "\n",
    "    try:\n",
    "        for query_path in query_paths:\n",
    "            query = database_load_query(query_path=query_path)\n",
    "            database_execute_sql_query(conn=conn, query=query)\n",
    "    finally:\n",
    "        # Making sure connection is always closed\n",
    "        database_close(conn=conn)\n",
    "\n",
    "\n",
    "def database_drop(db_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Delete the DuckDB database file at the specified path.\n",
    "\n",
    "    Args:\n",
    "        db_path (Path): Path to the DuckDB database file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    db_path.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b6172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-02 13:37:23,356: INFO: common: Directory: artifacts/sql created successfully.]\n"
     ]
    }
   ],
   "source": [
    "db_location = Path('artifacts/sql/air_quality.db')\n",
    "ddl_location = Path('src/AQI/sql/ddl')\n",
    "creation_or_deletion = True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        if creation_or_deletion:\n",
    "            database_initialize(db_path=db_location, ddl_dir=ddl_location)\n",
    "        else:\n",
    "            database_drop(db_path=db_location)\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd80c2b",
   "metadata": {},
   "source": [
    "# 3. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234a2aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from jinja2 import Template\n",
    "from pathlib import Path\n",
    "\n",
    "from AQI.utils.common import load_json\n",
    "from AQI.utils.logger import get_logger\n",
    "\n",
    "# Initializing the logger to test for exploration purposes\n",
    "logger = get_logger(\"test\")\n",
    "\n",
    "def insert_api_data(location_path: Path, db_path: Path, query_path: Path, start_date: str | None, end_date: str | None, file_name: str = \"OpenAQ\") -> None:\n",
    "    \"\"\"Insert OpenAQ data into database over a date range.\"\"\"\n",
    "    # Step 1: Get location IDs\n",
    "    location_ids = extract_location_ids(file_path=location_path)\n",
    "\n",
    "    # Step 2: Connect to DB\n",
    "    conn = database_connect(db_path=db_path)\n",
    "\n",
    "    # Step 3: Tracking passes and fails\n",
    "    passed, failed = 0, 0\n",
    "\n",
    "    try:\n",
    "        # Step 4: Load SQL template\n",
    "        query_template  = database_load_query(query_path)\n",
    "\n",
    "        # Step 5: Parse dates\n",
    "        start = parse_date(start_date)\n",
    "        end = parse_date(end_date, default=datetime.now())\n",
    "\n",
    "        # Step 6: Generate date range\n",
    "        date_range = generate_range(start, end)\n",
    "\n",
    "        # Step 7: Loop over IDs and months\n",
    "        for location_id in location_ids:\n",
    "            for curr_date in date_range:\n",
    "                api_path = render_openaq_path(location_id, year=str(curr_date.year), month=str(curr_date.month))\n",
    "                extraction_query = render_query(query_template, api_path, file_name)\n",
    "                try:\n",
    "                    database_execute_sql_query(conn=conn, query=extraction_query)\n",
    "                    passed += 1\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed: id={location_id}, date={curr_date:%Y-%m}, error={e}\")\n",
    "                    failed += 1\n",
    "\n",
    "                logger.info(f\"{passed} / {passed + failed} ingested out of {len(location_ids)}\")\n",
    "    \n",
    "    finally:\n",
    "        # Step 8: Close the database regardless of exceptions\n",
    "        database_close(conn=conn)\n",
    "\n",
    "\n",
    "def extract_location_ids(file_path: Path) -> list[str]:\n",
    "    \"\"\"Extract location IDs as strings from a JSON file.\"\"\"\n",
    "    locations = load_json(file_path)\n",
    "    return [str(id) for id in locations.keys()]\n",
    "\n",
    "\n",
    "def parse_date(date_str: str | None, default: datetime | None = None) -> datetime:\n",
    "    \"\"\"Parse YYYY-MM string into datetime, fallback to default or now().\"\"\"\n",
    "    if date_str:\n",
    "        return datetime.strptime(date_str, \"%Y-%m\")\n",
    "    return default or datetime.now()\n",
    "\n",
    "\n",
    "def generate_range(start: datetime, end: datetime) -> list[datetime]:\n",
    "    \"\"\"Return list of month starts between start and end (inclusive).\"\"\"\n",
    "    return [start + relativedelta(months=i) for i in range((end.year - start.year) * 12 + (end.month - start.month + 1))]\n",
    "\n",
    "\n",
    "def render_query(query: str, api_path: str, file_name: str) -> str:\n",
    "    \"\"\"Render SQL query with template substitution.\"\"\"\n",
    "    return Template(query).render(data_file_path=api_path, file_name=file_name)\n",
    "\n",
    "\n",
    "def render_openaq_path(location_id: str, year: str, month: str) -> str:\n",
    "    \"\"\"Generate OpenAQ S3 path for a location and month.\"\"\"\n",
    "    return f\"s3://openaq-data-archive/records/csv.gz/locationid={location_id}/year={year}/month={month.zfill(2)}/*.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66517f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-02 13:48:35,009: INFO: common: JSON file succesfully loaded form: artifacts/data/sensor_locations.json]\n",
      "Failed: id=386, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=386/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=642, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=642/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=662, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=662/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=853, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=853/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=974, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=974/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=984, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=984/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=2193, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=2193/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=8749, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=8749/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=1236043, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=1236043/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=1738519, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=1738519/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=1775647, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=1775647/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=2453305, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=2453305/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=2453313, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=2453313/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=2616564, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=2616564/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=3145067, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=3145067/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=3145068, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=3145068/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=3145069, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=3145069/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=3145070, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=3145070/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=3145072, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=3145072/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=3145073, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=3145073/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=3145074, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=3145074/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=3400913, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=3400913/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=3406357, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=3406357/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=4419380, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=4419380/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=4727343, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=4727343/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=5066205, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=5066205/year=2025/month=01/*.csv.gz\"\n",
      "Failed: id=5238263, date=2025-01, error=IO Error: No files found that match the pattern \"s3://openaq-data-archive/records/csv.gz/locationid=5238263/year=2025/month=01/*.csv.gz\"\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        location_path = Path(\"artifacts/data/sensor_locations.json\")\n",
    "        db_path = Path(\"artifacts/sql/air_quality.db\")\n",
    "        query_path = Path(\"src/AQI/sql/dml/010_insert_measurements.sql\")\n",
    "\n",
    "        start_date = \"2025-01\"\n",
    "        end_date = \"2025-01\"\n",
    "\n",
    "        insert_api_data(location_path, db_path, query_path, start_date, end_date)\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1bea2",
   "metadata": {},
   "source": [
    "# 4. Presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad59e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def create_presentations(db_path: Path, presentation_dir: Path) -> None:\n",
    "    # Step 1: Connect to DB\n",
    "    conn = database_connect(db_path=db_path)\n",
    "\n",
    "    # Step 2: Aggregate all .sql file paths\n",
    "    query_paths = database_aggregate_sql_paths(dir=presentation_dir)\n",
    "\n",
    "    try:\n",
    "        # Step 3: Execute all the queries\n",
    "        for query_path in query_paths:\n",
    "            query = database_load_query(query_path=query_path)\n",
    "            database_execute_sql_query(conn=conn, query=query)\n",
    "    finally:\n",
    "        # Step 4: Making sure connection is always closed\n",
    "        database_close(conn=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a08385",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        db_path = Path(\"artifacts/sql/air_quality.db\")\n",
    "        presentation_dir = Path(\"src/AQI/sql/presentation\")\n",
    "\n",
    "        create_presentations(db_path, presentation_dir)\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa8061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
